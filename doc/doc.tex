%        File: doc.tex
%     Created: tor feb 08 01:00  2018 C
% Last Change: tor feb 08 01:00  2018 C
%
\documentclass[a4paper]{article}
\usepackage{amsmath}
\newcommand{\trm}[1]{\textrm{#1}}
\begin{document}
\section{Introduction}
\section{Monte Carlo}
In statistical physics averages are calculated from 
\begin{equation}
  \langle A\rangle = \frac{1}{Z}\trm{Tr} e^{-H/T} = \sum_x A(x) P(x)
  \label{}
\end{equation}
where  $P(x) = (1/Z)exp(-H(x))$ is the Boltzmann distribution.
The practical and convievable way to evaluate these averages using Monte Carlo is to use importance sampling, i.e. do not form averages from uniformly random system configurations, but instead generate configurations that are Boltzmann distributed.   
Thus thermal Monte Carlo averages have the form 
\begin{equation}
  \langle A \rangle = \frac{1}{N} \sum_x A(x) \pm \frac{\sigma	}{\sqrt N}
  \label{}
\end{equation}
where the states $x$ are Boltzmann distributed.
However, the Boltzmann distribution may be unsuitable for some systems/configurations we want to study, so we can use any other distribution as 
\begin{equation}
  \langle A \rangle = \frac{\frac{1}{N}\sum_y \frac{A(y) e^{-H(x)/T}}{P'(y)}}{\frac{1}{N}\sum_y \frac{e^{-H(y)/T}}{P'(y)}}  
  \label{}
\end{equation}
 where the states $y$ are distributed according to $P'(y)$.

 \\
 Importance sampling is a way of reducing the error in the Monte Carlo estimate. Instead of choosing sample points distributed uniformly, one can try to choose the most probable states. Since thermal systems are Boltzmann-distributed, we want a way to randomly generate states distributed according to the Boltzmann distribution.
 \section{Markov process}
 A Markovian process is one for which the probility of getting to any state in the system is determined solely by the current state. I.e. the probability of going from state $x_i$ to $x_{j}$ is given by a transition probability $w(x_i \rightarrow x_j)$. The master equation describing the evolution of the probability distribution can then be written $P(x_i $<++>
 
\section{Detailed Balance}
\section{Wolff Algorithm}

\section{Helium-4}
\section{XY-model}
\section{Histrogram extrapolation}
Histogram extrapolation is a method to extract more data from a run. 
Averages are calculated as
\begin{equation}
  \langle A \rangle_{\beta_0} =  \frac{\sum_{x}A_x e^{-\beta_0 H_x}}{\sum_{x}e^{-\beta_0 H_x}}
  \label{}
\end{equation}
To get the average of A at some different temperature, say $\beta_1$, we can do
\begin{align}
  \langle A\rangle_{\beta_1} =  \frac{\sum_{x}A_x e^{-\beta_1 H_x}}{\sum_{x}e^{-\beta_1 H_x}} = \\
  = \frac{\sum_x A_x e^{-(\beta_1 - \beta_0)H_x} e^{-\beta_0 H_x}}{\sum_x e^{-(\beta_1 - \beta_0)H_x}e^{-\beta_0 H_x}} = \\
  = \frac{\langle A e^{-(\beta_1 - \beta_0)H}\rangle_{\beta_0}}{\langle e^{-(\beta_1 - \beta_0)H}\rangle_{\beta_0}}
\end{align}
Since the value of $abs(\beta_1 -\beta_0)$ will be small in practice, and the value of the energy will increase with the systemsize, precision will be lost in the calculation of $\exp\left( \beta_1 - \beta_0 \right)H_x$. To mitigate this, one can subtract a constant from the energy of the system, $H_max$, since a constant shift in energy will not change expectation values, since it just factors out of both sums and cancels.
\section{Binder cumulant}
The quantity $b =\frac{\langle M^4 \rangle}{\langle M^2\rangle^2}$ is useful in determining the critical temperature, as it in the thermodynamic limit $L\rightarrow \infty $ essentially becomes a heaviside function, discontinous at the critical temperature. Whats more is that the intersection point for Binder cumulants of different finite sizes depend weakly on the size, thus 
\end{document}

